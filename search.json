[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "2026-website",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "assignment4.html",
    "href": "assignment4.html",
    "title": "assignment4.qmd",
    "section": "",
    "text": "Databases 1-1) Uber Purpose: connecting passengers and drivers We can select the ride based on our budget and time circumstances We select the destination as a passenger and it shows the distance, type of vehicles( lux, shared ride, van, bike) with different fees. Then we select the option and wait for the driver. 1-2) Bank application Easier transactions and revieing statement or account balance in real time It has a first page showing the budget and in the second page showing our transaction. We can do deposit in the mobile application and transfer money. 1-3) Duolingo The purpose is making language learning easier and accessible. It is a language learning application. It saves my courses and time that I spend on the courses. It has different stages for each course and game while we are learning\nTeachers rank 2-1) purpose: I want to have a database of teachers and see easily what is their score in students opinion about the course and teacher easily without schools criteria and survey that does not show the real feedback of students. Function: students add their comments and score to the teacher platform and it is visible for all people. Also the person can be anonymous and do not need to add their name Simple interface design: The first page student can select the name of teacher- select the score- add comments and post it I would add comparison dashboard for teachers in same field same university or school 2-2) question website Purpose: for reporters and news agencies I want to design a platform to add their questions before meeting with president and if the ai in the website could find the previous answer will show them if they did not satisfy with the answer they can ask it again. Function: the database will remove repetitive questions and show the questions on the board for president without the need for chaos in the meeting and the answer will be typed by AI immediately. Interface: there is one page for asking question just this and it store the question and bring it up for president to see the questions\n\n2-3) purpose: volunteer database website to show all available voluntary locations for people. Function: charities or voluntary opportunities are available in this website in the first page. People can select their location and type of activities categories then they will see available voluntary opportunities then they will select. They will guide to the second page which is the information and requirements of that voluntary then if they want they can submit information ( name, email address and phone number). Interface: there are list of voluntary opportunities. People who are members of website.\n\nwhat are things that current databases cannot do? I think they cannot update themselves automatically. They cannot change their relationship by themselves and if the person change the schema that may cause many other effect on whole database it means that it is not easy to change the relationships after we define one way.\nlinkedin, whatsapp, youtube"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "assignment1.qmd",
    "section": "",
    "text": "To Explain or to Predict? They talked about the relationship between causal explanation and empirical prediction. The some fields causal explanatory model has a high prediction power. While in empirical model like NLP the focus is on empirical prediction. The main hypothesis in this study is causal versus predictive distinction has high effect on statistical modeling process and its results. Explanatory modeling and predictive modeling reflect the data mining and statistical analysis methos to explain and predict. And modeling means the whole process including definition, study design, and data collection for statistical usage. In this study they define explaining as causal explanation and explanatory needling as the use of statistical models for testing causal explanations. Predictive modeling uses data mining algorithms and statistical models to predict future observations until time t+k. these modeling summarized the data structure. While in causal theory (descriptive modeling) rely on measurable model to describe the data, like a regression model is used to capture dependent and independent variables to show the relationships between variables. They consider four area for differences between explanation and prediction models, including : Causation-association: in explanatory model f represents causal relationship, while in predictive model f records correlation between inputs and outputs. Theory data: in explanatory, f model is created based on the theory to be able to explain while in predictive, the explanatory and clarity of model is in lower priority than data. Retrospective-prospective: in explanatory relies on testing the hypothesis of previous or current observation, while in prediction assumes the future observations. Bias-variance: in explanatory modeling we attempt on minimizing the bias to obtain more accurate representation. While in predictive models the try to maximize the combination of bias and estimation variance to reach improved empirical precision. These are the steps in the statistical modeling process: Define goal, design study and collect data, prepare data, eda, choose variables, choose methods, evaluate, validate, and model selection, use mode and report\nThey said consider both explanation power and prediction power as two dimension, as they are different qualities. There are some explanatory model have some level of predictive power to be considered scientifically useful and there are some predictive models have sufficient explanatory power to be scientifically useful. While , there exist predictive models that do not properly “explain” yet are scientifically valuable. (Bill Langford, Woit, 2006, pages x xii). Therefore, we should define our goal to optimize the right criteria and report both qualities to provide a complete picture of the model. Finally as statistics focuses on inference and less focus on predictive analysis, machine learning has been created.\nStatistical modeling Two cultures One culture is data are generated by a given data model Second culture use algorithms and treats the data mechanism as unknown As statistical community relies on data models, it kept statisticians from working a large range of interesting problems. In the article Leo Brieman defines two goal in analyzing data. 1)prediction: predict future responses to future input variables 2) information: extract information about how nature connects response variables to input variables. He defines two different approaches toward the goals Data modeling cuture. It assumes a stocustic data model for inside of the black box. The value of parameters are estimated from data and model The algorithmic modeling culture. The inside of the box is unknown and an algorithmic operatrion can accurately predict. After several projects and statistical research he found that the belief in the infallibility of data models was almost religious. It is a strange phenomenon- once model created, it becomes truth and the conclusion from it are infallible. While it is not correct. When we make small changes in the model can change complete while it is accurate. He said the picture of which covariates are important can vary significantly between two models having about same deviance. Aggregate over a large set of competing models can reduce the non-uniqueness while improving accuracy He believes that statisticians should focus on solving the problem instead of asking what data model they can create. The best solution might ba algorithmic model or data model or combination of both. So they need to use wide variety of tools. The roots of statistics is lie on working with data and checking theory against data. And he hoped that this century our field will return t its toots."
  },
  {
    "objectID": "assignment5.html",
    "href": "assignment5.html",
    "title": "assignment5.qmd",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "assignment5.html#quarto",
    "href": "assignment5.html#quarto",
    "title": "assignment5.qmd",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "assignment5.html#running-code",
    "href": "assignment5.html#running-code",
    "title": "assignment5.qmd",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  }
]